{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "A corpus (plural: corpora) is essentially a large collection of text. This text can range from multiple paragraphs to entire books, or even a compilation of various texts. The primary purpose of a corpus is to serve as a dataset for linguistic research and NLP applications. For instance, in this discussion, we are using a corpus derived from a paragraph of Indian Wikipedia to illustrate various concepts."
      ],
      "metadata": {
        "id": "cOSGaCftTsCl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLksWNdpTlXc",
        "outputId": "d77dffac-1808-418b-adef-b9fc87d740ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "India is a country in South Asia. It is the seventh-largest country by land area, the second-most populous country, and the most populous democracy in the world.\n"
          ]
        }
      ],
      "source": [
        "corpus = \"India is a country in South Asia. It is the seventh-largest country by land area, the second-most populous country, and the most populous democracy in the world.\"\n",
        "print(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding Vocabulary"
      ],
      "metadata": {
        "id": "7RZjM3JpTwc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vocabulary, in the context of NLP, refers to the set of unique words in a given corpus. The size of the vocabulary is a critical factor in various text analysis tasks. It represents the total number of unique words after preprocessing steps like removing stop words and special characters.\n",
        "\n"
      ],
      "metadata": {
        "id": "coJMXgShT0nf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the Corpus\n",
        "\n",
        "Preprocessing is a crucial step in text analysis. It involves cleaning and preparing the text data to make it suitable for further analysis. Here are the steps involved in preprocessing:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Tokenization: Splitting the corpus into individual words or tokens.\n",
        "*   Stop Words Removal: Removing common words that do not contribute much to the meaning of the text (e.g., \"is\", \"the\", \"and\").\n",
        "*   Special Characters Removal: Removing punctuation marks and other non-alphabetic characters.\n",
        "*   Converting to Lowercase: Converting all words to lowercase to ensure uniformity.\n",
        "\n",
        "\n",
        "\n",
        "Letâ€™s walk through the preprocessing steps with code examples."
      ],
      "metadata": {
        "id": "LaK2QjYwUe03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to tokenize the corpus and remove stop words:"
      ],
      "metadata": {
        "id": "amZgxFrQUx_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "# nltk.download('all')\n",
        "\n",
        "# Tokenize the corpus\n",
        "tokens = word_tokenize(corpus)\n",
        "\n",
        "# Remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "print(filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N-8XfkxTqEr",
        "outputId": "c043b575-93df-4757-e6d4-77938f73be8b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['India', 'country', 'South', 'Asia', '.', 'seventh-largest', 'country', 'land', 'area', ',', 'second-most', 'populous', 'country', ',', 'populous', 'democracy', 'world', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing Special Characters"
      ],
      "metadata": {
        "id": "J51zfx0mWAVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_tokens = [word for word in filtered_tokens if word.isalpha()]\n",
        "print(filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2KSybELUdnV",
        "outputId": "0e56e5fc-c903-4bdd-c005-a3ec44cf104b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['India', 'country', 'South', 'Asia', 'country', 'land', 'area', 'populous', 'country', 'populous', 'democracy', 'world']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating Vocabulary Size"
      ],
      "metadata": {
        "id": "ryCnG-GfW2XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = set(filtered_tokens)\n",
        "vocab_size = len(unique_words)\n",
        "print(f\"Vocabulary Size: {vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEE5sSn4WC24",
        "outputId": "7627b4b7-d471-41e1-895e-6d65430d8ae1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MHWxuDARW3oY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}