{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhPbvdRpZUZ_",
        "outputId": "02fbf1dc-45cc-4730-bd7b-eac40699ad87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'is': 1, 'coffee': 2, 'hot': 3, 'water': 4, 'cold': 5}\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tok = Tokenizer()\n",
        "\n",
        "# Define a sample corpus\n",
        "corpus = ['coffee is hot', 'water is cold']\n",
        "\n",
        "# Fit the tokenizer on the corpus\n",
        "tok.fit_on_texts(corpus)\n",
        "\n",
        "# View the word-to-index mapping\n",
        "print(tok.word_index)\n",
        "\n",
        "# The tokenizer assigns a unique integer to each word based on frequency. For instance, is (most frequent) gets index 1, while cold gets 5."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert new texts to sequences\n",
        "sequences = tok.texts_to_sequences(['water is hot', 'black coffee is cold'])\n",
        "print(sequences) # 'black' is ignored (not in vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2csb29KNb4fv",
        "outputId": "d4d320b3-b51c-438b-e53d-e0e76a1ec45a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4, 1, 3], [2, 1, 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Handling Out-of-Vocabulary (OOV) Words**\n",
        "\n",
        "Words not seen during training (e.g., black in the example above) are ignored by default. To handle such cases, use the oov_token parameter:"
      ],
      "metadata": {
        "id": "HPZGJXTUcQJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer with OOV support\n",
        "tok = Tokenizer(oov_token='<OOV>')\n",
        "\n",
        "# Fit on the corpus\n",
        "tok.fit_on_texts(corpus)\n",
        "\n",
        "# View updated word index\n",
        "print(tok.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFGbPsiucEJ2",
        "outputId": "78139c76-1cdc-434c-c39d-af58f7311c66"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<OOV>': 1, 'is': 2, 'coffee': 3, 'hot': 4, 'water': 5, 'cold': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, unseen words like black are replaced with the OOV token:"
      ],
      "metadata": {
        "id": "aUaUQb_TcYb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tok.texts_to_sequences(['water is hot', 'black coffee is cold'])\n",
        "print(sequences) # 'black' â†’ 1 (OOV)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uNoHaVJcVHx",
        "outputId": "a206bfd4-fa55-49c4-db48-f177df6fb5d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5, 2, 4], [1, 3, 2, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Limiting Vocabulary Size**\n",
        "\n",
        "Large corpora can lead to massive vocabularies. Use num_words to restrict the number of tokens:"
      ],
      "metadata": {
        "id": "9c5-CrKUchSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Limit vocabulary to the top 5 most frequent words\n",
        "tok = Tokenizer(num_words=6)\n",
        "tok.fit_on_texts(corpus)\n",
        "\n",
        "print(tok.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4piHCZ5cc3-",
        "outputId": "7df5f58b-affb-47d0-ff65-36294592bf97"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'is': 1, 'coffee': 2, 'hot': 3, 'water': 4, 'cold': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When converting text, only top num_words are retained:"
      ],
      "metadata": {
        "id": "R0TWfPN3crOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tok.texts_to_sequences(['water is hot', 'black coffee is cold'])\n",
        "print(sequences)# 'black' is excluded (not in top 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "746REOGLcntG",
        "outputId": "ece88851-c816-440d-e787-acd0ae048419"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4, 1, 3], [2, 1, 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uz9z2llYcqv-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}