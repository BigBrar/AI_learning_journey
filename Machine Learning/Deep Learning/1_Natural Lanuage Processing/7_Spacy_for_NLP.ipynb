{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importing spacy and loading en_core_web_lg**\n",
        "\n",
        "en_core_web_lg is basically loading the english language into an object. We could also use en_core_web_sm for a smaller dictionary of english language."
      ],
      "metadata": {
        "id": "PbNZm8HjkVvx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NxtVSOxtkQYZ"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simple Tokenization**\n",
        "\n",
        "We have already seen the tokenization using nltk. Let's see how to do tokenization using spacy."
      ],
      "metadata": {
        "id": "DqJROQqakf4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s=nlp('GFG is looking for data science interns')\n",
        "for token in s:\n",
        "    print(token.text)\n",
        "\n",
        "s=nlp(u'The cost of Iphone in U.K is 699$')\n",
        "for token in s:\n",
        "    print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJs-UFK6keq1",
        "outputId": "20e40a9e-1c90-4449-9885-afb92c4290f2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GFG\n",
            "is\n",
            "looking\n",
            "for\n",
            "data\n",
            "science\n",
            "interns\n",
            "The\n",
            "cost\n",
            "of\n",
            "Iphone\n",
            "in\n",
            "U.K\n",
            "is\n",
            "699\n",
            "$\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is smart enough to consider U.K as a single token"
      ],
      "metadata": {
        "id": "T2UsI-a6k3dP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pos_ - it indicates part of speech\n",
        "for token in s:\n",
        "    print(token.text,token.pos_)\n",
        "# It helps you identify the grammatical role of each word in your text, useful for text analysis and NLP tasks."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUSti6jCkq_C",
        "outputId": "3601b672-0686-4ed9-e8bf-6274a3fcd2b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The DET\n",
            "cost NOUN\n",
            "of ADP\n",
            "Iphone PROPN\n",
            "in ADP\n",
            "U.K PROPN\n",
            "is AUX\n",
            "699 NUM\n",
            "$ SYM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   U.K is a pronoun\n",
        "*   cost is noun\n",
        "*   699 is a number\n",
        "*   $ is a symbol\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3G-993Sclgf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "jgEnpa2wlp_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentence Tokenization**"
      ],
      "metadata": {
        "id": "NbtGGMp-lsJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s=nlp(u\"This is the first sentence. I gave given fullstop please check. Let's study now\")\n",
        "for sentence in s.sents:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L53kfcpak7Xg",
        "outputId": "dd71b1de-0df7-4a4b-cac5-dc6406ee66e1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the first sentence.\n",
            "I gave given fullstop please check.\n",
            "Let's study now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "08ERxVMDpVTO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stop Words using spacy"
      ],
      "metadata": {
        "id": "EER38gZLpWgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "print(nlp.Defaults.stop_words)\n",
        "\n",
        "print()\n",
        "\n",
        "print(len(nlp.Defaults.stop_words))\n",
        "\n",
        "#  These are the list of all the stop words present by default.\n",
        "\n",
        "#  We will now try to remove all of these words and start working towards our future analysis.\n",
        "\n",
        "#  There are a total of 326 stop words present."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhMnaxRHlwUk",
        "outputId": "1c688e6c-495c-4a4b-bcd1-57d128c74de8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'besides', 'rather', 'this', 'then', 'hundred', 'am', 'became', 'eleven', 'least', 'toward', 'hence', 'hereafter', 'an', 'has', '’ll', 'indeed', 'full', 'when', 'bottom', 'she', 'would', 'always', 'nine', 'well', 'whereupon', 'he', 'most', 'due', 'namely', 'somewhere', 'along', 'two', 'still', 'keep', 'thereafter', 'per', 'something', 'towards', 'others', 'by', 'become', 'therein', 'do', 'herself', 'you', 'all', 'now', 'both', 'nor', 'twenty', 'too', 'mostly', 'yours', 'amongst', 'various', 'make', 'and', 'at', 'will', 'much', 'thence', 'whether', 'everywhere', 'your', 'fifty', 'four', '’re', 'than', 'yourself', 'ten', 'to', 'until', 'latter', 'sometime', 'anyhow', 'it', 'move', 'could', 'anyone', 'therefore', 'the', 'even', 'they', \"'s\", '’d', 'twelve', 'while', 'third', 'thus', 'beforehand', 'afterwards', 'over', 'whereas', 'only', 'moreover', 'give', 'none', 'off', 'these', 'from', 'because', 'of', 'many', 'behind', '‘d', '’m', 'is', 'did', 'everything', 'though', 'n‘t', 'becomes', 'alone', 'own', 'themselves', 'onto', 'via', '‘re', 'ever', 'latterly', 'thereby', 'perhaps', 'next', 'everyone', 'some', 'among', 'i', 'noone', 'throughout', 'thru', 'where', 'such', 'as', 'however', 'other', 'had', 'whither', 'whoever', 'show', 'another', 'with', 'former', 'can', 'made', 'n’t', 'me', 'were', 'really', 'already', 'except', 'name', 'anyway', 'have', 'side', '‘m', 'up', 'be', 'below', 'unless', 'several', 'hers', 'there', 'may', 'serious', 'go', 'either', 'part', 'seems', 'eight', 'never', 'mine', 'anywhere', '‘ll', 'seemed', 'fifteen', 'around', 'each', 'that', 'for', 'seeming', 'almost', 'five', 'her', 'regarding', 'using', 'being', '‘s', 'further', 'between', 'less', 'no', 'itself', 'enough', 'their', 'above', 'cannot', 'sometimes', 'otherwise', \"'ll\", 'whereafter', 'about', 'does', 'more', 'top', 'seem', 'down', 'been', 'but', 'anything', 'somehow', 'after', 'ca', 'a', 'formerly', 'front', 'last', 'those', 'call', 'amount', 'myself', 'empty', 'often', 'whatever', 'forty', \"'m\", 'its', 'was', 'must', 'again', 'nobody', 'should', 'on', 'what', 'see', 'since', 'three', 'why', 'every', 'against', 'not', 'under', 'elsewhere', 'once', 'else', 'put', 'get', 'one', 'who', 'take', 'together', 'before', 'nevertheless', 'wherever', 'into', 'please', 'beyond', 'them', 'herein', 'whom', 'whole', 'how', 'doing', 'ours', 'thereupon', 'us', 'hereby', 'if', 'through', 'same', 'done', 'used', 'wherein', 'someone', 'few', 'ourselves', 'very', 'during', 'whence', 'across', 'back', 'or', 'meanwhile', 'although', 'yet', 'first', 'whereby', 'nowhere', \"'ve\", 'beside', 'himself', 'say', \"n't\", 'hereupon', 'in', 'his', 'six', 'whose', 'nothing', '’s', 'also', 'quite', 'him', 'we', 'becoming', 'so', 'which', 'upon', '‘ve', 'sixty', 'neither', 'here', 'whenever', 'without', 'are', 'just', 'might', \"'re\", 'yourselves', 'within', 'my', \"'d\", 'out', 'our', 'any', '’ve', 're'}\n",
            "\n",
            "326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to check if a particular Word is stop word or not\n",
        "print(nlp.vocab['is'].is_stop)\n",
        "\n",
        "print(nlp.vocab['GFG'].is_stop)\n",
        "\n",
        "print(nlp.vocab['hello'].is_stop)\n",
        "\n",
        "print(nlp.vocab['was'].is_stop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5c_cCZwpl9d",
        "outputId": "80afe7ae-ac76-447a-8f8c-e8e0ca086cbc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n",
            "False\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If we want to add stop words of our own specific choice then we can easily do it.\n",
        "print(f\"Before: {nlp.vocab['i.e'].is_stop}\")\n",
        "nlp.vocab['i.e'].is_stop = True\n",
        "print(f\"After: {nlp.vocab['i.e'].is_stop}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT9vjfcGp4CD",
        "outputId": "04f18139-d58a-46c4-8fd9-9cad8b3b512d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: False\n",
            "After: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let’s see how to remove a stop word now\n",
        "print(f\"Before: {nlp.vocab['done'].is_stop}\")\n",
        "nlp.Defaults.stop_words.remove('done')\n",
        "nlp.vocab['done'].is_stop = False\n",
        "\n",
        "print(f\"After: {nlp.vocab['done'].is_stop}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzTDautxqJiy",
        "outputId": "13e83cf9-d45f-46f9-ff53-770ed074c0e7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: True\n",
            "After: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's see how we can remove stop words from out corpus\n",
        "txt='''Data science is the study of data. Like biological sciences is a study of biology, physical sciences, it's the study of physical reactions. Data is real, data has real properties, and we need to study them if we're going to work on them. Data Science involves data and some signs. It is a process, not an event. It is the process of using data to understand too many different things, to understand the world. Let Suppose when you have a model or proposed explanation of a problem, and you try to validate that proposed explanation or model with your data. It is the skill of unfolding the insights and trends that are hiding (or abstract) behind data. It's when you translate data into a story. So use storytelling to generate insight. And with these insights, you can make strategic choices for a company or an institution. We can also define data science as a field that is about processes and systems to extract data of various forms and from various resources whether the data is unstructured or structured.\n",
        "The definition and the name came up in the 1980s and 1990s when some professors, IT Professionals, scientists were looking into the statistics curriculum, and they thought it would be better to call it data science and then later on data analytics derived.\n",
        "'''\n",
        "txt=txt.replace('\\n','')\n",
        "txt=txt.replace('  ','')\n",
        "txt=txt.strip()\n",
        "txt = nlp(txt)"
      ],
      "metadata": {
        "id": "67r7VLrkqpjM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding Stopwords from the corpus:"
      ],
      "metadata": {
        "id": "2I5kLsizrq9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set()\n",
        "for token in txt:\n",
        "  if token.is_stop:\n",
        "    stop_words.add(token.text)\n",
        "print(stop_words)\n",
        "print(len(stop_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZF2DK1ZrrWd",
        "outputId": "9fe36aec-e0e5-41da-8a30-fb40524b4050"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the', 'also', 'of', 'they', \"'s\", 'many', 'are', 'can', 'call', 'And', 'then', 'behind', 'whether', 'some', 'We', 'we', 'were', 'your', \"'re\", 'into', 'is', 'or', 'you', 'not', 'an', 'It', 'has', 'about', 'them', 'name', 'to', 'when', 'have', 'as', 'in', 'would', 'up', 'IT', 'that', 'for', 'be', 'too', 'it', 'these', 'if', 'various', 'on', 'The', 'using', 'So', 'make', 'from', 'a', 'and', 'with'}\n",
            "55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing corpus without the stopwords\n",
        "' '.join([token.text for token in txt if not token.is_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "PGu7V8DOr6zj",
        "outputId": "cd91f9c2-510a-4c39-e48f-d39a361f156f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Data science study data . Like biological sciences study biology , physical sciences , study physical reactions . Data real , data real properties , need study going work . Data Science involves data signs . process , event . process data understand different things , understand world . Let Suppose model proposed explanation problem , try validate proposed explanation model data . skill unfolding insights trends hiding ( abstract ) data . translate data story . use storytelling generate insight . insights , strategic choices company institution . define data science field processes systems extract data forms resources data unstructured structured . definition came 1980s 1990s professors , Professionals , scientists looking statistics curriculum , thought better data science later data analytics derived .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CTzjSvqFtC1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Synonyms and Antonyms**"
      ],
      "metadata": {
        "id": "wv2nsUlxtD-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Synonym**\n",
        "\n",
        "A synonym is a word or phrase with the same or nearly the same meaning as another word or phrase. Thus, the words that are similar in meaning are called synonyms.\n",
        "\n",
        "**Antonym**\n",
        "\n",
        "An antonym is a term or phrase that has the opposite meaning.\n",
        "\n",
        "**Wordnet**\n",
        "\n",
        "WordNet is the lexical database i.e. dictionary for the English language, specifically designed for natural language processing."
      ],
      "metadata": {
        "id": "TRG7362UtJo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "#  we also need to download wordnet specifically with nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjYe88Snsfod",
        "outputId": "222deef9-6311-4035-c254-d5130354f2be"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the definiton() function to get the definition of the word.\n",
        "syn = wordnet.synsets('Book')\n",
        "print(syn[0].definition())\n",
        "# using the [0] index while printing because there are many synonyms of book\n",
        "# and we have just used the first one"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwMqEaQStYhi",
        "outputId": "25f9e874-8abd-4372-8d1f-2d9db9410726"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a written work or composition that has been published (printed on pages bound together)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting the synonyms**"
      ],
      "metadata": {
        "id": "FQ7ewIIOt55K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "synonyms = []\n",
        "for s in wordnet.synsets('Happy'):\n",
        "  for lemma in s.lemmas():\n",
        "    synonyms.append(lemma.name())\n",
        "\n",
        "print(synonyms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObI7qN0DtbMg",
        "outputId": "7c9d78e0-288e-4278-9cad-d8e82fb7bdfd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['happy', 'felicitous', 'happy', 'glad', 'happy', 'happy', 'well-chosen']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting the antonyms**"
      ],
      "metadata": {
        "id": "5oAJ7_ZJuLOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ant = []\n",
        "for a in wordnet.synsets('Healthy'):\n",
        "  for lemma in a.lemmas():\n",
        "    if lemma.antonyms():\n",
        "      ant.append(lemma.antonyms()[0].name())\n",
        "\n",
        "print(ant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uruv10vUuGM1",
        "outputId": "34b70ce2-7aed-425e-86b0-5d2eb159b93d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['unhealthy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mv8zUjyHuZj3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}